{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "brinks_test.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sahil97/30MinTask/blob/master/brinks_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "3xMQ1xqwCucU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import nltk, re, time\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from collections import namedtuple"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sYSgPoD7C-Z8",
        "colab_type": "code",
        "outputId": "1903e0e6-251d-4f7b-81d7-a4776acc4084",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Rx3BQL7jCuci",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "imdb_train = pd.read_csv(\"gdrive/My Drive/ML Data/labeledTrainData.tsv\", delimiter=\"\\t\")\n",
        "amazon_train = pd.read_csv('gdrive/My Drive/ML Data/amazon_cells_labelled.txt', delimiter=\"\\t\",header=-1)\n",
        "yelp_train = pd.read_csv('gdrive/My Drive/ML Data/yelp_labelled.txt',delimiter=\"\\t\",header=-1)\n",
        "\n",
        "\n",
        "test = pd.read_csv(\"gdrive/My Drive/ML Data/testData.tsv\", delimiter=\"\\t\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "84onRnS_Cuco",
        "colab_type": "code",
        "outputId": "df628f6b-138a-4ba4-a575-451ff6b4deb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "imdb_train.drop(['id'],axis=1,inplace=True)\n",
        "imdb_train.head()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>With all this stuff going down at the moment w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>It must be assumed that those who praised this...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment                                             review\n",
              "0          1  With all this stuff going down at the moment w...\n",
              "1          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
              "2          0  The film starts with a manager (Nicholas Bell)...\n",
              "3          0  It must be assumed that those who praised this...\n",
              "4          1  Superbly trashy and wondrously unpretentious 8..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "metadata": {
        "id": "7mkBQuuucQFE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# amazon_train.head()\n",
        "# amazon_train['sentiment'] = amazon_train[1]\n",
        "# amazon_train['review']=amazon_train[0]\n",
        "# amazon_train.drop([0,1],axis=1,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PtLY0qxEc8um",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#amazon_train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XzVx8oc-dTTv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# yelp_train.head()\n",
        "# yelp_train['sentiment'] = yelp_train[1]\n",
        "# yelp_train['review']=yelp_train[0]\n",
        "# yelp_train.drop([0,1],axis=1,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wBUNofF8cinc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# yelp_train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vstE5SPICucv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# test.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yXAQV5tSd0Rh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # print(amazon_train.shape)\n",
        "# print(yelp_train.shape)\n",
        "# print(imdb_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sc8N1lw6dd5o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(\"gdrive/My Drive/ML Data/train_data.csv\", delimiter=\"\\t\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kFzZiW_yCuc0",
        "colab_type": "code",
        "outputId": "377cf8c6-b40f-4f91-dbed-a965f64ee605",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(train.shape)\n",
        "print(test.shape)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(21000, 3)\n",
            "(25000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NgwnxqTGCuc8",
        "colab_type": "code",
        "outputId": "d71549db-2001-45b2-b20e-08d3d28e2bfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "for i in range(3):\n",
        "    print(train.review[i])\n",
        "    print()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With all this stuff going down at the moment with MJ i've started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ's feeling towards the press and also the obvious message of drugs are bad m'kay.<br /><br />Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring. Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him.<br /><br />The actual feature film bit when it finally starts is only on for 20 minutes or so excluding the Smooth Criminal sequence and Joe Pesci is convincing as a psychopathic all powerful drug lord. Why he wants MJ dead so bad is beyond me. Because MJ overheard his plans? Nah, Joe Pesci's character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno, maybe he just hates MJ's music.<br /><br />Lots of cool things in this like MJ turning into a car and a robot and the whole Speed Demon sequence. Also, the director must have had the patience of a saint when it came to filming the kiddy Bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene.<br /><br />Bottom line, this movie is for people who like MJ on one level or another (which i think is most people). If not, then stay away. It does try and give off a wholesome message and ironically MJ's bestest buddy in this movie is a girl! Michael Jackson is truly one of the most talented people ever to grace this planet but is he guilty? Well, with all the attention i've gave this subject....hmmm well i don't know because people can be different behind closed doors, i know this for a fact. He is either an extremely nice but stupid guy or one of the most sickest liars. I hope he is not the latter.\n",
            "\n",
            "\\The Classic War of the Worlds\\\" by Timothy Hines is a very entertaining film that obviously goes to great effort and lengths to faithfully recreate H. G. Wells' classic book. Mr. Hines succeeds in doing so. I, and those who watched his film with me, appreciated the fact that it was not the standard, predictable Hollywood fare that comes out every year, e.g. the Spielberg version with Tom Cruise that had only the slightest resemblance to the book. Obviously, everyone looks for different things in a movie. Those who envision themselves as amateur \\\"critics\\\" look only to criticize everything they can. Others rate a movie on more important bases,like being entertained, which is why most people never agree with the \\\"critics\\\". We enjoyed the effort Mr. Hines put into being faithful to H.G. Wells' classic novel, and we found it to be very entertaining. This made it easy to overlook what the \\\"critics\\\" perceive to be its shortcomings.\"\n",
            "\n",
            "The film starts with a manager (Nicholas Bell) giving welcome investors (Robert Carradine) to Primal Park . A secret project mutating a primal animal using fossilized DNA, like ¨Jurassik Park¨, and some scientists resurrect one of nature's most fearsome predators, the Sabretooth tiger or Smilodon . Scientific ambition turns deadly, however, and when the high voltage fence is opened the creature escape and begins savagely stalking its prey - the human visitors , tourists and scientific.Meanwhile some youngsters enter in the restricted area of the security center and are attacked by a pack of large pre-historical animals which are deadlier and bigger . In addition , a security agent (Stacy Haiduk) and her mate (Brian Wimmer) fight hardly against the carnivorous Smilodons. The Sabretooths, themselves , of course, are the real star stars and they are astounding terrifyingly though not convincing. The giant animals savagely are stalking its prey and the group run afoul and fight against one nature's most fearsome predators. Furthermore a third Sabretooth more dangerous and slow stalks its victims.<br /><br />The movie delivers the goods with lots of blood and gore as beheading, hair-raising chills,full of scares when the Sabretooths appear with mediocre special effects.The story provides exciting and stirring entertainment but it results to be quite boring .The giant animals are majority made by computer generator and seem totally lousy .Middling performances though the players reacting appropriately to becoming food.Actors give vigorously physical performances dodging the beasts ,running,bound and leaps or dangling over walls . And it packs a ridiculous final deadly scene. No for small kids by realistic,gory and violent attack scenes . Other films about Sabretooths or Smilodon are the following : ¨Sabretooth(2002)¨by James R Hickox with Vanessa Angel, David Keith and John Rhys Davies and the much better ¨10.000 BC(2006)¨ by Roland Emmerich with with Steven Strait, Cliff Curtis and Camilla Belle. This motion picture filled with bloody moments is badly directed by George Miller and with no originality because takes too many elements from previous films. Miller is an Australian director usually working for television (Tidal wave, Journey to the center of the earth, and many others) and occasionally for cinema ( The man from Snowy river, Zeus and Roxanne,Robinson Crusoe ). Rating : Below average, bottom of barrel.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Q0rtbgpaCudC",
        "colab_type": "code",
        "outputId": "6f32a5fc-6ce7-4b7e-8237-aeb876e5c44a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "# Check for any null values\n",
        "print(train.isnull().sum())\n",
        "print(test.isnull().sum())"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unnamed: 0    0\n",
            "sentiment     0\n",
            "review        0\n",
            "dtype: int64\n",
            "id        0\n",
            "review    0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3Puh4T-ECudN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def clean_text(text, remove_stopwords=True):\n",
        "    '''Clean the text, with the option to remove stopwords'''\n",
        "    \n",
        "    # Convert words to lower case and split them\n",
        "    text = text.lower().split()\n",
        "\n",
        "    # Optionally, remove stop words\n",
        "    if remove_stopwords:\n",
        "        stops = set(stopwords.words(\"english\"))\n",
        "        text = [w for w in text if not w in stops]\n",
        "    \n",
        "    text = \" \".join(text)\n",
        "\n",
        "    # Clean the text\n",
        "    text = re.sub(r\"<br />\", \" \", text)\n",
        "    text = re.sub(r\"[^a-z]\", \" \", text)\n",
        "    text = re.sub(r\"   \", \" \", text) # Remove any extra spaces\n",
        "    text = re.sub(r\"  \", \" \", text)\n",
        "    \n",
        "    # Remove punctuation from text\n",
        "    text = ''.join([c for c in text if c not in punctuation])\n",
        "    \n",
        "    # Return a list of words\n",
        "    return(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PyTA_hjqCudT",
        "colab_type": "code",
        "outputId": "dcd726ed-1c7f-4e8f-a40b-28e732be5239",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "train_clean = []\n",
        "for review in train.review:\n",
        "    train_clean.append(clean_text(review))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aeaHXmwACudW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_clean = []\n",
        "for review in test.review:\n",
        "    test_clean.append(clean_text(review))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OmjsG9eXCudZ",
        "colab_type": "code",
        "outputId": "94ef5b09-90b5-4d5f-880b-7a312fece901",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "cell_type": "code",
      "source": [
        "# Inspect the cleaned reviews\n",
        "for i in range(3):\n",
        "    print(train_clean[i])\n",
        "    print()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "stuff going moment mj i ve started listening music watching odd documentary there watched wiz watched moonwalker again maybe want get certain insight guy thought really cool eighties maybe make mind whether guilty innocent moonwalker part biography part feature film remember going see cinema originally released subtle messages mj s feeling towards press also obvious message drugs bad m kay visually impressive course michael jackson unless remotely like mj anyway going hate find boring may call mj egotist consenting making movie mj fans would say made fans true really nice him the actual feature film bit finally starts minutes excluding smooth criminal sequence joe pesci convincing psychopathic powerful drug lord wants mj dead bad beyond me mj overheard plans nah joe pesci s character ranted wanted people know supplying drugs etc dunno maybe hates mj s music lots cool things like mj turning car robot whole speed demon sequence also director must patience saint came filming kiddy bad sequence usually directors hate working one kid let alone whole bunch performing complex dance scene bottom line movie people like mj one level another which think people not stay away try give wholesome message ironically mj s bestest buddy movie girl michael jackson truly one talented people ever grace planet guilty well attention i ve gave subject hmmm well know people different behind closed doors know fact either extremely nice stupid guy one sickest liars hope latter \n",
            "\n",
            " the classic war worlds timothy hines entertaining film obviously goes great effort lengths faithfully recreate h g wells classic book mr hines succeeds so i watched film me appreciated fact standard predictable hollywood fare comes every year e g spielberg version tom cruise slightest resemblance book obviously everyone looks different things movie envision amateur critics look criticize everything can others rate movie important bases like entertained people never agree critics enjoyed effort mr hines put faithful h g wells classic novel found entertaining made easy overlook critics perceive shortcomings \n",
            "\n",
            "film starts manager nicholas bell giving welcome investors robert carradine primal park secret project mutating primal animal using fossilized dna like jurassik park scientists resurrect one nature s fearsome predators sabretooth tiger smilodon scientific ambition turns deadly however high voltage fence opened creature escape begins savagely stalking prey human visitors tourists scientific meanwhile youngsters enter restricted area security center attacked pack large pre historical animals deadlier bigger addition security agent stacy haiduk mate brian wimmer fight hardly carnivorous smilodons sabretooths course real star stars astounding terrifyingly though convincing giant animals savagely stalking prey group run afoul fight one nature s fearsome predators furthermore third sabretooth dangerous slow stalks victims the movie delivers goods lots blood gore beheading hair raising chills full scares sabretooths appear mediocre special effects the story provides exciting stirring entertainment results quite boring the giant animals majority made computer generator seem totally lousy middling performances though players reacting appropriately becoming food actors give vigorously physical performances dodging beasts running bound leaps dangling walls packs ridiculous final deadly scene small kids realistic gory violent attack scenes films sabretooths smilodon following sabretooth  by james r hickox vanessa angel david keith john rhys davies much better  bc  roland emmerich steven strait cliff curtis camilla belle motion picture filled bloody moments badly directed george miller originality takes many elements previous films miller australian director usually working television tidal wave journey center earth many others occasionally cinema man snowy river zeus roxanne robinson crusoe rating average bottom barrel \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HvlqdIMHfffQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "39964bfc-7f08-4f00-a9c3-a7a1eba7b82f"
      },
      "cell_type": "code",
      "source": [
        "len(train_clean)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "metadata": {
        "id": "VfqJNGwTCudf",
        "colab_type": "code",
        "outputId": "b64a5529-e0f6-4962-ab0f-55725c904191",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# Tokenize the reviews\n",
        "all_reviews = train_clean + test_clean\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(all_reviews)\n",
        "print(\"Fitting is complete.\")\n",
        "\n",
        "train_seq = tokenizer.texts_to_sequences(train_clean)\n",
        "print(\"train_seq is complete.\")\n",
        "\n",
        "test_seq = tokenizer.texts_to_sequences(test_clean)\n",
        "print(\"test_seq is complete\")"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting is complete.\n",
            "train_seq is complete.\n",
            "test_seq is complete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Xv83bF8UCudj",
        "colab_type": "code",
        "outputId": "f29a85e6-3230-4acf-84db-5bf6c043b79b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Find the number of unique tokens\n",
        "word_index = tokenizer.word_index\n",
        "print(\"Words in index: %d\" % len(word_index))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Words in index: 93246\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bEukyBLACuds",
        "colab_type": "code",
        "outputId": "aa5f9095-e694-489c-a5ca-fc4e61ccb6e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "cell_type": "code",
      "source": [
        "# Inspect the reviews after they have been tokenized\n",
        "for i in range(3):\n",
        "    print(train_seq[i])\n",
        "    print()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[388, 66, 530, 10358, 6, 59, 502, 2614, 115, 83, 966, 661, 49, 243, 19748, 243, 22043, 189, 177, 88, 17, 716, 2891, 122, 108, 12, 386, 4298, 177, 24, 253, 710, 2383, 1448, 22043, 97, 5178, 97, 789, 3, 308, 66, 15, 409, 1958, 649, 1333, 4233, 10358, 1, 483, 929, 3435, 20, 584, 758, 1549, 22, 50, 6396, 2478, 1165, 178, 481, 1758, 760, 2778, 5, 10358, 463, 66, 658, 72, 309, 118, 495, 10358, 40595, 36243, 160, 2, 10358, 423, 11, 56, 25, 423, 228, 12, 130, 201, 10, 808, 789, 3, 112, 328, 527, 128, 16923, 3867, 2034, 736, 877, 12358, 1218, 13395, 989, 1118, 1911, 469, 10358, 300, 22, 639, 110, 10358, 12812, 2296, 16438, 877, 12358, 1, 44, 36244, 315, 21, 37, 16924, 1549, 402, 8908, 177, 4529, 10358, 1, 115, 541, 386, 96, 5, 10358, 1719, 404, 2647, 138, 2212, 2703, 736, 20, 92, 117, 4632, 5790, 197, 1497, 28498, 22, 736, 425, 1040, 658, 620, 4, 467, 184, 572, 138, 706, 3775, 1292, 855, 63, 1199, 267, 2, 21, 5, 10358, 4, 590, 70, 464, 28, 21, 248, 632, 153, 165, 99, 8019, 758, 3880, 10358, 1, 36245, 1695, 2, 176, 481, 1758, 313, 4, 1054, 21, 47, 1580, 1482, 2383, 16, 645, 6, 59, 406, 785, 6506, 16, 37, 21, 173, 453, 2347, 3093, 37, 114, 263, 476, 130, 318, 122, 4, 22044, 17932, 362, 1687]\n",
            "\n",
            "[10, 306, 236, 4234, 5294, 16439, 392, 3, 494, 217, 14, 794, 7853, 11150, 9496, 1913, 1121, 5295, 306, 218, 410, 16439, 3073, 175, 6, 243, 3, 110, 2290, 114, 1128, 756, 304, 2327, 194, 79, 207, 712, 1121, 4167, 274, 852, 4202, 4437, 4849, 218, 494, 192, 224, 173, 96, 2, 19116, 2798, 1476, 86, 6993, 148, 82, 323, 941, 2, 595, 12813, 5, 2538, 21, 35, 971, 1476, 371, 794, 410, 16439, 186, 3138, 1913, 1121, 5295, 306, 714, 159, 392, 25, 616, 5744, 1476, 12814, 5950]\n",
            "\n",
            "[3, 527, 1618, 5714, 2717, 677, 2263, 17933, 619, 5264, 12120, 894, 1029, 1166, 28499, 12120, 1862, 732, 40596, 10359, 5, 58151, 894, 3369, 12815, 4, 968, 1, 18542, 9017, 26820, 5354, 46867, 4088, 6001, 492, 2892, 106, 205, 30535, 6942, 1954, 1649, 1066, 892, 19749, 7057, 4986, 363, 7854, 8256, 4088, 2179, 7694, 2194, 13090, 564, 2348, 1512, 3405, 2695, 605, 1675, 1396, 1727, 30536, 1736, 1528, 2348, 1562, 8617, 36246, 4751, 2038, 58152, 565, 1058, 21209, 58153, 40597, 178, 68, 230, 264, 5923, 24071, 67, 1218, 1254, 1727, 19749, 7057, 4986, 412, 401, 16035, 565, 4, 968, 1, 18542, 9017, 4022, 869, 26820, 1842, 485, 10048, 1679, 10, 2, 1611, 4877, 541, 529, 625, 17410, 952, 5355, 6207, 249, 3015, 40597, 1011, 1410, 199, 245, 10, 18, 1637, 1186, 8909, 726, 2141, 100, 309, 10, 1254, 1727, 2320, 25, 1397, 19750, 237, 372, 2462, 24072, 342, 67, 2042, 13965, 5095, 1676, 80, 89, 99, 22045, 1859, 342, 16036, 13396, 597, 3106, 10190, 13966, 2810, 7224, 656, 438, 2892, 63, 246, 259, 823, 2253, 1229, 1504, 65, 43, 40597, 46867, 920, 26820, 978, 587, 1258, 40598, 6711, 2495, 581, 4147, 257, 8816, 4769, 19, 48, 12566, 9900, 46868, 2329, 17411, 4369, 5575, 7695, 7443, 1470, 397, 921, 1667, 361, 957, 497, 739, 3048, 3016, 250, 36, 850, 845, 43, 3048, 2156, 92, 425, 620, 703, 24073, 3631, 1311, 1512, 719, 36, 323, 1896, 409, 58, 10360, 2053, 17412, 28500, 4900, 40599, 611, 673, 1199, 5228]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rDDHO77XCud0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Find the length of reviews\n",
        "lengths = []\n",
        "for review in train_seq:\n",
        "    lengths.append(len(review))\n",
        "\n",
        "for review in test_seq:\n",
        "    lengths.append(len(review))\n",
        "\n",
        "# Create a dataframe so that the values can be inspected\n",
        "lengths = pd.DataFrame(lengths, columns=['counts'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UpHV4CygCud6",
        "colab_type": "code",
        "outputId": "62923069-4b00-40a5-8fef-257b165c0e1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "cell_type": "code",
      "source": [
        "lengths.counts.describe()"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    46000.000000\n",
              "mean       112.870109\n",
              "std         93.428205\n",
              "min          1.000000\n",
              "25%         59.000000\n",
              "50%         85.000000\n",
              "75%        139.000000\n",
              "max       1488.000000\n",
              "Name: counts, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "metadata": {
        "id": "kL1rEyc4Cud_",
        "colab_type": "code",
        "outputId": "ce2eeb50-2dd6-41d1-ad09-895bca57fd40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "print(np.percentile(lengths.counts, 80))\n",
        "print(np.percentile(lengths.counts, 85))\n",
        "print(np.percentile(lengths.counts, 90))\n",
        "print(np.percentile(lengths.counts, 95))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "160.0\n",
            "187.0\n",
            "228.0\n",
            "305.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hFIUUqx3CueE",
        "colab_type": "code",
        "outputId": "0ddec618-6c07-4d7b-b1d1-666c3f08e159",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# Pad and truncate the questions so that they all have the same length.\n",
        "max_review_length = 200\n",
        "\n",
        "train_pad = pad_sequences(train_seq, maxlen = max_review_length)\n",
        "print(\"train_pad is complete.\")\n",
        "\n",
        "test_pad = pad_sequences(test_seq, maxlen = max_review_length)\n",
        "print(\"test_pad is complete.\")"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_pad is complete.\n",
            "test_pad is complete.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mhHkqvI3CueI",
        "colab_type": "code",
        "outputId": "d336ea7e-5b1f-43dc-b5dc-3dc5c4816bf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "cell_type": "code",
      "source": [
        "# Inspect the reviews after padding has been completed. \n",
        "for i in range(3):\n",
        "    print(train_pad[i,:100])\n",
        "    print()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[   97  5178    97   789     3   308    66    15   409  1958   649  1333\n",
            "  4233 10358     1   483   929  3435    20   584   758  1549    22    50\n",
            "  6396  2478  1165   178   481  1758   760  2778     5 10358   463    66\n",
            "   658    72   309   118   495 10358 40595 36243   160     2 10358   423\n",
            "    11    56    25   423   228    12   130   201    10   808   789     3\n",
            "   112   328   527   128 16923  3867  2034   736   877 12358  1218 13395\n",
            "   989  1118  1911   469 10358   300    22   639   110 10358 12812  2296\n",
            " 16438   877 12358     1    44 36244   315    21    37 16924  1549   402\n",
            "  8908   177  4529 10358]\n",
            "\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "\n",
            "[ 7057  4986   363  7854  8256  4088  2179  7694  2194 13090   564  2348\n",
            "  1512  3405  2695   605  1675  1396  1727 30536  1736  1528  2348  1562\n",
            "  8617 36246  4751  2038 58152   565  1058 21209 58153 40597   178    68\n",
            "   230   264  5923 24071    67  1218  1254  1727 19749  7057  4986   412\n",
            "   401 16035   565     4   968     1 18542  9017  4022   869 26820  1842\n",
            "   485 10048  1679    10     2  1611  4877   541   529   625 17410   952\n",
            "  5355  6207   249  3015 40597  1011  1410   199   245    10    18  1637\n",
            "  1186  8909   726  2141   100   309    10  1254  1727  2320    25  1397\n",
            " 19750   237   372  2462]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jiVxd-WOCueL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Creating the training and validation sets\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(train_pad, train.sentiment, test_size = 0.15, random_state = 2)\n",
        "x_test = test_pad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AH7Z11A7CueO",
        "colab_type": "code",
        "outputId": "6fcd8420-57d3-4756-8da2-0928f2056952",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# Inspect the shape of the data\n",
        "print(x_train.shape)\n",
        "print(x_valid.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(17850, 200)\n",
            "(3150, 200)\n",
            "(25000, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0WrA28ytCueU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_batches(x, y, batch_size):\n",
        "    '''Create the batches for the training and validation data'''\n",
        "    n_batches = len(x)//batch_size\n",
        "    x, y = x[:n_batches*batch_size], y[:n_batches*batch_size]\n",
        "    for ii in range(0, len(x), batch_size):\n",
        "        yield x[ii:ii+batch_size], y[ii:ii+batch_size]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3lKnJPbRCueW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_test_batches(x, batch_size):\n",
        "    '''Create the batches for the testing data'''\n",
        "    n_batches = len(x)//batch_size\n",
        "    x = x[:n_batches*batch_size]\n",
        "    for ii in range(0, len(x), batch_size):\n",
        "        yield x[ii:ii+batch_size]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yh2JPFb9EMi_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def lstm_cell(lstm_size, keep_prob):\n",
        "    lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
        "    drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob)\n",
        "    return drop"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "-P0d7dYxCueZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_rnn(n_words, embed_size, batch_size, lstm_size, num_layers, \n",
        "              dropout, learning_rate, multiple_fc, fc_units):\n",
        "    '''Build the Recurrent Neural Network'''\n",
        "\n",
        "    tf.reset_default_graph()\n",
        "\n",
        "    # Declare placeholders we'll feed into the graph\n",
        "    with tf.name_scope('inputs'):\n",
        "        inputs = tf.placeholder(tf.int32, [None, None], name='inputs')\n",
        "\n",
        "    with tf.name_scope('labels'):\n",
        "        labels = tf.placeholder(tf.int32, [None, None], name='labels')\n",
        "\n",
        "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
        "\n",
        "    # Create the embeddings\n",
        "    with tf.name_scope(\"embeddings\"):\n",
        "        embedding = tf.Variable(tf.random_uniform((n_words, embed_size), -1, 1))\n",
        "        embed = tf.nn.embedding_lookup(embedding, inputs)\n",
        "\n",
        "    # Build the RNN layers\n",
        "    with tf.name_scope(\"RNN_layers\"):\n",
        "        cell = tf.contrib.rnn.MultiRNNCell([lstm_cell(lstm_size, keep_prob) for _ in range(num_layers)])\n",
        "    \n",
        "    # Set the initial state\n",
        "    with tf.name_scope(\"RNN_init_state\"):\n",
        "        initial_state = cell.zero_state(batch_size, tf.float32)\n",
        "\n",
        "    # Run the data through the RNN layers\n",
        "    with tf.name_scope(\"RNN_forward\"):\n",
        "        outputs, final_state = tf.nn.dynamic_rnn(cell, embed,\n",
        "                                                 initial_state=initial_state)    \n",
        "    \n",
        "    # Create the fully connected layers\n",
        "    with tf.name_scope(\"fully_connected\"):\n",
        "        \n",
        "        # Initialize the weights and biases\n",
        "        weights = tf.truncated_normal_initializer(stddev=0.1)\n",
        "        biases = tf.zeros_initializer()\n",
        "        \n",
        "        dense = tf.contrib.layers.fully_connected(outputs[:, -1],\n",
        "                                                  num_outputs = fc_units,\n",
        "                                                  activation_fn = tf.sigmoid,\n",
        "                                                  weights_initializer = weights,\n",
        "                                                  biases_initializer = biases)\n",
        "        dense = tf.contrib.layers.dropout(dense, keep_prob)\n",
        "        \n",
        "        # Depending on the iteration, use a second fully connected layer\n",
        "        if multiple_fc == True:\n",
        "            dense = tf.contrib.layers.fully_connected(dense,\n",
        "                                                      num_outputs = fc_units,\n",
        "                                                      activation_fn = tf.sigmoid,\n",
        "                                                      weights_initializer = weights,\n",
        "                                                      biases_initializer = biases)\n",
        "            dense = tf.contrib.layers.dropout(dense, keep_prob)\n",
        "    \n",
        "    # Make the predictions\n",
        "    with tf.name_scope('predictions'):\n",
        "        predictions = tf.contrib.layers.fully_connected(dense, \n",
        "                                                        num_outputs = 1, \n",
        "                                                        activation_fn=tf.sigmoid,\n",
        "                                                        weights_initializer = weights,\n",
        "                                                        biases_initializer = biases)\n",
        "        tf.summary.histogram('predictions', predictions)\n",
        "    \n",
        "    # Calculate the cost\n",
        "    with tf.name_scope('cost'):\n",
        "        cost = tf.losses.mean_squared_error(labels, predictions)\n",
        "        tf.summary.scalar('cost', cost)\n",
        "    \n",
        "    # Train the model\n",
        "    with tf.name_scope('train'):    \n",
        "        optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
        "\n",
        "    # Determine the accuracy\n",
        "    with tf.name_scope(\"accuracy\"):\n",
        "        correct_pred = tf.equal(tf.cast(tf.round(predictions), tf.int32), labels)\n",
        "        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "        tf.summary.scalar('accuracy', accuracy)\n",
        "    \n",
        "    # Merge all of the summaries\n",
        "    merged = tf.summary.merge_all()    \n",
        "\n",
        "    # Export the nodes \n",
        "    export_nodes = ['inputs', 'labels', 'keep_prob', 'initial_state', 'final_state','accuracy',\n",
        "                    'predictions', 'cost', 'optimizer', 'merged']\n",
        "    Graph = namedtuple('Graph', export_nodes)\n",
        "    local_dict = locals()\n",
        "    graph = Graph(*[local_dict[each] for each in export_nodes])\n",
        "    \n",
        "    return graph"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Giwc4VLQg9l8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ea78b59a-fd98-44fe-c5d1-c48ac7d1f04b"
      },
      "cell_type": "code",
      "source": [
        "!mkdir 'gdrive/My Drive/Model_checkpoints/trial2'"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘gdrive/My Drive/Model_checkpoints/trial2’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R-03-caECueb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(model, epochs, log_string):\n",
        "    '''Train the RNN'''\n",
        "\n",
        "    saver = tf.train.Saver()\n",
        "    \n",
        "    with tf.Session() as sess:\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "\n",
        "        # Used to determine when to stop the training early\n",
        "        valid_loss_summary = []\n",
        "        \n",
        "        # Keep track of which batch iteration is being trained\n",
        "        iteration = 0\n",
        "\n",
        "        print()\n",
        "        print(\"Training Model: {}\".format(log_string))\n",
        "\n",
        "        train_writer = tf.summary.FileWriter('./logs/3/train/{}'.format(log_string), sess.graph)\n",
        "        valid_writer = tf.summary.FileWriter('./logs/3/valid/{}'.format(log_string))\n",
        "\n",
        "        for e in range(epochs):\n",
        "            state = sess.run(model.initial_state)\n",
        "            \n",
        "            # Record progress with each epoch\n",
        "            train_loss = []\n",
        "            train_acc = []\n",
        "            val_acc = []\n",
        "            val_loss = []\n",
        "\n",
        "            with tqdm(total=len(x_train)) as pbar:\n",
        "                for _, (x, y) in enumerate(get_batches(x_train, y_train, batch_size), 1):\n",
        "                    feed = {model.inputs: x,\n",
        "                            model.labels: y[:, None],\n",
        "                            model.keep_prob: dropout,\n",
        "                            model.initial_state: state}\n",
        "                    summary, loss, acc, state, _ = sess.run([model.merged, \n",
        "                                                             model.cost, \n",
        "                                                             model.accuracy, \n",
        "                                                             model.final_state, \n",
        "                                                             model.optimizer], \n",
        "                                                            feed_dict=feed)                \n",
        "                    \n",
        "                    # Record the loss and accuracy of each training batch\n",
        "                    train_loss.append(loss)\n",
        "                    train_acc.append(acc)\n",
        "                    \n",
        "                    # Record the progress of training\n",
        "                    train_writer.add_summary(summary, iteration)\n",
        "                    \n",
        "                    iteration += 1\n",
        "                    pbar.update(batch_size)\n",
        "            \n",
        "            # Average the training loss and accuracy of each epoch\n",
        "            avg_train_loss = np.mean(train_loss)\n",
        "            avg_train_acc = np.mean(train_acc) \n",
        "\n",
        "            val_state = sess.run(model.initial_state)\n",
        "            with tqdm(total=len(x_valid)) as pbar:\n",
        "                for x, y in get_batches(x_valid, y_valid, batch_size):\n",
        "                    feed = {model.inputs: x,\n",
        "                            model.labels: y[:, None],\n",
        "                            model.keep_prob: 1,\n",
        "                            model.initial_state: val_state}\n",
        "                    summary, batch_loss, batch_acc, val_state = sess.run([model.merged, \n",
        "                                                                          model.cost, \n",
        "                                                                          model.accuracy, \n",
        "                                                                          model.final_state], \n",
        "                                                                         feed_dict=feed)\n",
        "                    \n",
        "                    # Record the validation loss and accuracy of each epoch\n",
        "                    val_loss.append(batch_loss)\n",
        "                    val_acc.append(batch_acc)\n",
        "                    pbar.update(batch_size)\n",
        "            \n",
        "            # Average the validation loss and accuracy of each epoch\n",
        "            avg_valid_loss = np.mean(val_loss)    \n",
        "            avg_valid_acc = np.mean(val_acc)\n",
        "            valid_loss_summary.append(avg_valid_loss)\n",
        "            \n",
        "            # Record the validation data's progress\n",
        "            valid_writer.add_summary(summary, iteration)\n",
        "\n",
        "            # Print the progress of each epoch\n",
        "            print(\"Epoch: {}/{}\".format(e, epochs),\n",
        "                  \"Train Loss: {:.3f}\".format(avg_train_loss),\n",
        "                  \"Train Acc: {:.3f}\".format(avg_train_acc),\n",
        "                  \"Valid Loss: {:.3f}\".format(avg_valid_loss),\n",
        "                  \"Valid Acc: {:.3f}\".format(avg_valid_acc))\n",
        "\n",
        "            # Stop training if the validation loss does not decrease after 3 epochs\n",
        "            if avg_valid_loss > min(valid_loss_summary):\n",
        "                print(\"No Improvement.\")\n",
        "                stop_early += 1\n",
        "                if stop_early == 3:\n",
        "                    break   \n",
        "            \n",
        "            # Reset stop_early if the validation loss finds a new low\n",
        "            # Save a checkpoint of the model\n",
        "            else:\n",
        "                print(\"New Record!\")\n",
        "                stop_early = 0\n",
        "                checkpoint = \"gdrive/My Drive/Model_checkpoints/trial2/sentiment_{}.ckpt\".format(log_string)\n",
        "                saver.save(sess, checkpoint)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jQBVCGMqCueg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# The default parameters of the model\n",
        "n_words = len(word_index)\n",
        "embed_size = 300\n",
        "batch_size = 2\n",
        "lstm_size = 128\n",
        "num_layers = 2\n",
        "dropout = 0.5\n",
        "learning_rate = 0.01\n",
        "epochs = 100\n",
        "multiple_fc = False\n",
        "fc_units = 256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YPHW6AoVCuej",
        "colab_type": "code",
        "outputId": "f597d6ec-8c54-47af-b5bf-73eb1b34207d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1169
        }
      },
      "cell_type": "code",
      "source": [
        "# Train the model with the desired tuning parameters\n",
        "for lstm_size in [64,128]:\n",
        "    for multiple_fc in [True, False]:\n",
        "        for fc_units in [128, 256]:\n",
        "            log_string = 'ru={},fcl={},fcu={}'.format(lstm_size,\n",
        "                                                      multiple_fc,\n",
        "                                                      fc_units)\n",
        "            model = build_rnn(n_words = n_words, \n",
        "                              embed_size = embed_size,\n",
        "                              batch_size = batch_size,\n",
        "                              lstm_size = lstm_size,\n",
        "                              num_layers = num_layers,\n",
        "                              dropout = dropout,\n",
        "                              learning_rate = learning_rate,\n",
        "                              multiple_fc = multiple_fc,\n",
        "                              fc_units = fc_units)            \n",
        "            train(model, epochs, log_string)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training Model: ru=64,fcl=True,fcu=128\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 99%|█████████▉| 17750/17850 [00:29<00:00, 571.41it/s]\n",
            " 95%|█████████▌| 3000/3150 [00:02<00:00, 1265.72it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0/100 Train Loss: 0.223 Train Acc: 0.664 Valid Loss: 0.171 Valid Acc: 0.781\n",
            "New Record!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 48%|████▊     | 8500/17850 [00:14<00:15, 599.59it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-113-a015fca02b1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m                               \u001b[0mmultiple_fc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiple_fc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                               fc_units = fc_units)            \n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-80-1edf42a9288c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, epochs, log_string)\u001b[0m\n\u001b[1;32m     39\u001b[0m                                                              \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                                                              model.optimizer], \n\u001b[0;32m---> 41\u001b[0;31m                                                             feed_dict=feed)                \n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                     \u001b[0;31m# Record the loss and accuracy of each training batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "QL5oCwmh7Cs0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "05b7d4fd-56b3-4b69-f8b6-0c0bef00f8a7"
      },
      "cell_type": "code",
      "source": [
        "brinks_pad"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    0,     0,     0, ..., 21100,   683,  9610],\n",
              "       [    0,     0,     0, ...,  2732,   238, 51085],\n",
              "       [    0,     0,     0, ...,  7900,  9191,  3656],\n",
              "       ...,\n",
              "       [    0,     0,     0, ...,  5191,  4462, 10162],\n",
              "       [    0,     0,     0, ...,     0,    29,   212],\n",
              "       [    0,     0,     0, ...,   344,    14,  3439]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "metadata": {
        "id": "5xPMDipN7JPj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "14aae5d1-dd6f-4324-a51d-87d34bbeb424"
      },
      "cell_type": "code",
      "source": [
        "test_pad"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    0,     0,     0, ...,  4291,  3967,   930],\n",
              "       [    0,     0,     0, ...,     9,  3498,  1555],\n",
              "       [    0,     0,     0, ..., 17619,     1,   380],\n",
              "       ...,\n",
              "       [    0,     0,     0, ...,   228,    18,   391],\n",
              "       [    0,     0,     0, ...,   200,    29, 10331],\n",
              "       [    0,     0,     0, ...,   132,  1830,     4]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "metadata": {
        "id": "I8T5OkMsCuer",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_predictions(lstm_size, multiple_fc, fc_units, checkpoint):\n",
        "    '''Predict the sentiment of the testing data'''\n",
        "    \n",
        "    # Record all of the predictions\n",
        "    all_preds = []\n",
        "\n",
        "    model = build_rnn(n_words = n_words, \n",
        "                      embed_size = embed_size,\n",
        "                      batch_size = batch_size,\n",
        "                      lstm_size = lstm_size,\n",
        "                      num_layers = num_layers,\n",
        "                      dropout = dropout,\n",
        "                      learning_rate = learning_rate,\n",
        "                      multiple_fc = multiple_fc,\n",
        "                      fc_units = fc_units) \n",
        "    \n",
        "    with tf.Session() as sess:\n",
        "        saver = tf.train.Saver()\n",
        "        # Load the model\n",
        "        saver.restore(sess, checkpoint)\n",
        "        test_state = sess.run(model.initial_state)\n",
        "        for _, x in enumerate(get_test_batches(test_pad, batch_size), 1):\n",
        "            feed = {model.inputs: x,\n",
        "                    model.keep_prob: 1,\n",
        "                    model.initial_state: test_state}\n",
        "            predictions = sess.run(model.predictions, feed_dict=feed)\n",
        "            for pred in predictions:\n",
        "                all_preds.append(float(pred))\n",
        "                \n",
        "    return all_preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r0lnegUC658x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "nRHdNwveCuew",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "checkpoint1 = \"gdrive/My Drive/Model_checkpoints/trial2/sentiment_ru=128,fcl=False,fcu=256.ckpt\"\n",
        "checkpoint2 = \"gdrive/My Drive/Model_checkpoints/trial2/sentiment_ru=128,fcl=False,fcu=128.ckpt\"\n",
        "checkpoint3 = \"gdrive/My Drive/Model_checkpoints/trial2/sentiment_ru=64,fcl=True,fcu=256.ckpt\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VaMUuG366613",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-l88Oq9YCuez",
        "colab_type": "code",
        "outputId": "51903a13-4a22-46a7-aebd-5294141cfe7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1084
        }
      },
      "cell_type": "code",
      "source": [
        "# Make predictions using the best 3 models\n",
        "predictions1 = make_predictions(128, False, 256, checkpoint1)\n",
        "predictions2 = make_predictions(128, False, 128, checkpoint2)\n",
        "predictions3 = make_predictions(64, True, 256, checkpoint3)"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from gdrive/My Drive/Model_checkpoints/trial2/sentiment_ru=128,fcl=False,fcu=256.ckpt\n",
            "INFO:tensorflow:Restoring parameters from gdrive/My Drive/Model_checkpoints/trial2/sentiment_ru=128,fcl=False,fcu=128.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-150-1c0d8317db7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpredictions1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredictions2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpredictions3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-148-41d7075fa4ec>\u001b[0m in \u001b[0;36mmake_predictions\u001b[0;34m(lstm_size, multiple_fc, fc_units, checkpoint)\u001b[0m\n\u001b[1;32m     24\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                     model.initial_state: test_state}\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0mall_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "-QzbveI6Nm1c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17034
        },
        "outputId": "3915ab35-8c26-4709-8208-bf9201dbf36f"
      },
      "cell_type": "code",
      "source": [
        "predictions1"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9769830703735352,\n",
              " 0.011080026626586914,\n",
              " 0.486637145280838,\n",
              " 0.5805355906486511,\n",
              " 0.7314826250076294,\n",
              " 0.1490570306777954,\n",
              " 0.21622255444526672,\n",
              " 0.11603870987892151,\n",
              " 0.009724825620651245,\n",
              " 0.03026154637336731,\n",
              " 0.017169713973999023,\n",
              " 0.4152761697769165,\n",
              " 0.17688080668449402,\n",
              " 0.6220370531082153,\n",
              " 0.23107418417930603,\n",
              " 0.8626309633255005,\n",
              " 0.10771194100379944,\n",
              " 0.07638686895370483,\n",
              " 0.9191462993621826,\n",
              " 0.010332435369491577,\n",
              " 0.010252624750137329,\n",
              " 0.6721173524856567,\n",
              " 0.9686622023582458,\n",
              " 0.012571275234222412,\n",
              " 0.6145703196525574,\n",
              " 0.014154046773910522,\n",
              " 0.009472072124481201,\n",
              " 0.8827129602432251,\n",
              " 0.013550102710723877,\n",
              " 0.014898091554641724,\n",
              " 0.9727814793586731,\n",
              " 0.9761784076690674,\n",
              " 0.955047607421875,\n",
              " 0.013719797134399414,\n",
              " 0.6349088549613953,\n",
              " 0.976715624332428,\n",
              " 0.022113382816314697,\n",
              " 0.01229676604270935,\n",
              " 0.6900664567947388,\n",
              " 0.03481161594390869,\n",
              " 0.07908719778060913,\n",
              " 0.009900718927383423,\n",
              " 0.2294045090675354,\n",
              " 0.9742465019226074,\n",
              " 0.9760715365409851,\n",
              " 0.9762983322143555,\n",
              " 0.04705232381820679,\n",
              " 0.9744375944137573,\n",
              " 0.011232107877731323,\n",
              " 0.32277971506118774,\n",
              " 0.021797984838485718,\n",
              " 0.9616445302963257,\n",
              " 0.8667017817497253,\n",
              " 0.9718468189239502,\n",
              " 0.028263479471206665,\n",
              " 0.9575708508491516,\n",
              " 0.9717878103256226,\n",
              " 0.9712481498718262,\n",
              " 0.5989755988121033,\n",
              " 0.01310431957244873,\n",
              " 0.0195009708404541,\n",
              " 0.7099767923355103,\n",
              " 0.21183615922927856,\n",
              " 0.10545399785041809,\n",
              " 0.9766628742218018,\n",
              " 0.7481390237808228,\n",
              " 0.1235685646533966,\n",
              " 0.9646239280700684,\n",
              " 0.03231745958328247,\n",
              " 0.8744083046913147,\n",
              " 0.17485058307647705,\n",
              " 0.972722053527832,\n",
              " 0.8595256805419922,\n",
              " 0.13180211186408997,\n",
              " 0.7660542726516724,\n",
              " 0.9280709624290466,\n",
              " 0.976094663143158,\n",
              " 0.010204195976257324,\n",
              " 0.009060323238372803,\n",
              " 0.009505867958068848,\n",
              " 0.009470164775848389,\n",
              " 0.20475876331329346,\n",
              " 0.5021148324012756,\n",
              " 0.08225730061531067,\n",
              " 0.968296229839325,\n",
              " 0.009856969118118286,\n",
              " 0.968779444694519,\n",
              " 0.974669337272644,\n",
              " 0.9758203625679016,\n",
              " 0.010127007961273193,\n",
              " 0.04486978054046631,\n",
              " 0.4519585371017456,\n",
              " 0.9764237403869629,\n",
              " 0.8445057272911072,\n",
              " 0.9771823883056641,\n",
              " 0.009899109601974487,\n",
              " 0.973853588104248,\n",
              " 0.0099869966506958,\n",
              " 0.014443814754486084,\n",
              " 0.00975838303565979,\n",
              " 0.9343111515045166,\n",
              " 0.2854342460632324,\n",
              " 0.008899480104446411,\n",
              " 0.8965293169021606,\n",
              " 0.38211849331855774,\n",
              " 0.00994083285331726,\n",
              " 0.9768890142440796,\n",
              " 0.33602434396743774,\n",
              " 0.9731634855270386,\n",
              " 0.00948747992515564,\n",
              " 0.9738016724586487,\n",
              " 0.967330813407898,\n",
              " 0.9773865342140198,\n",
              " 0.010654091835021973,\n",
              " 0.9754959940910339,\n",
              " 0.9660577178001404,\n",
              " 0.9723811149597168,\n",
              " 0.9550613164901733,\n",
              " 0.030299872159957886,\n",
              " 0.9767328500747681,\n",
              " 0.03334972262382507,\n",
              " 0.9724423885345459,\n",
              " 0.04283663630485535,\n",
              " 0.3590238690376282,\n",
              " 0.9750517010688782,\n",
              " 0.9678325653076172,\n",
              " 0.37557336688041687,\n",
              " 0.08091917634010315,\n",
              " 0.8657044768333435,\n",
              " 0.9365202784538269,\n",
              " 0.55832839012146,\n",
              " 0.18191641569137573,\n",
              " 0.9448042511940002,\n",
              " 0.9683384895324707,\n",
              " 0.009382277727127075,\n",
              " 0.9261109828948975,\n",
              " 0.971540093421936,\n",
              " 0.9727437496185303,\n",
              " 0.9675585627555847,\n",
              " 0.9768263101577759,\n",
              " 0.5728870630264282,\n",
              " 0.9716446399688721,\n",
              " 0.052849531173706055,\n",
              " 0.9147880673408508,\n",
              " 0.5621958374977112,\n",
              " 0.9447625875473022,\n",
              " 0.9706066846847534,\n",
              " 0.05395236611366272,\n",
              " 0.011378735303878784,\n",
              " 0.9768289923667908,\n",
              " 0.9498919248580933,\n",
              " 0.02313232421875,\n",
              " 0.009780973196029663,\n",
              " 0.011387646198272705,\n",
              " 0.9778336882591248,\n",
              " 0.9753441214561462,\n",
              " 0.01007157564163208,\n",
              " 0.16805100440979004,\n",
              " 0.8650728464126587,\n",
              " 0.9642226696014404,\n",
              " 0.9738543033599854,\n",
              " 0.9722057580947876,\n",
              " 0.971242368221283,\n",
              " 0.9720829129219055,\n",
              " 0.010241299867630005,\n",
              " 0.06088840961456299,\n",
              " 0.022709786891937256,\n",
              " 0.9510856866836548,\n",
              " 0.009977549314498901,\n",
              " 0.008780717849731445,\n",
              " 0.09205484390258789,\n",
              " 0.972811222076416,\n",
              " 0.5800239443778992,\n",
              " 0.3925163745880127,\n",
              " 0.8878467082977295,\n",
              " 0.01081019639968872,\n",
              " 0.9666013717651367,\n",
              " 0.2957457900047302,\n",
              " 0.7939448356628418,\n",
              " 0.021374821662902832,\n",
              " 0.16873234510421753,\n",
              " 0.2613694667816162,\n",
              " 0.9760721325874329,\n",
              " 0.915618896484375,\n",
              " 0.11548161506652832,\n",
              " 0.9703423976898193,\n",
              " 0.009708762168884277,\n",
              " 0.018827885389328003,\n",
              " 0.9747339487075806,\n",
              " 0.9550804495811462,\n",
              " 0.01215517520904541,\n",
              " 0.330505907535553,\n",
              " 0.010364621877670288,\n",
              " 0.1000579297542572,\n",
              " 0.971494197845459,\n",
              " 0.015373170375823975,\n",
              " 0.9761875867843628,\n",
              " 0.3629198670387268,\n",
              " 0.06502091884613037,\n",
              " 0.9694366455078125,\n",
              " 0.9753790497779846,\n",
              " 0.4155949056148529,\n",
              " 0.5888034105300903,\n",
              " 0.009373486042022705,\n",
              " 0.9757819175720215,\n",
              " 0.9655483365058899,\n",
              " 0.9719350337982178,\n",
              " 0.013882726430892944,\n",
              " 0.013872474431991577,\n",
              " 0.009895414113998413,\n",
              " 0.8486342430114746,\n",
              " 0.8659142255783081,\n",
              " 0.9119980335235596,\n",
              " 0.9743274450302124,\n",
              " 0.9746255874633789,\n",
              " 0.4547479748725891,\n",
              " 0.05644997954368591,\n",
              " 0.009042441844940186,\n",
              " 0.02520740032196045,\n",
              " 0.009776026010513306,\n",
              " 0.9764904379844666,\n",
              " 0.0273934006690979,\n",
              " 0.9447076320648193,\n",
              " 0.9764708876609802,\n",
              " 0.661815881729126,\n",
              " 0.1405806839466095,\n",
              " 0.9468636512756348,\n",
              " 0.7351014614105225,\n",
              " 0.010815471410751343,\n",
              " 0.8760449290275574,\n",
              " 0.2661841809749603,\n",
              " 0.9757691621780396,\n",
              " 0.018190085887908936,\n",
              " 0.9720577597618103,\n",
              " 0.7129794955253601,\n",
              " 0.02025425434112549,\n",
              " 0.9671367406845093,\n",
              " 0.08750352263450623,\n",
              " 0.08646300435066223,\n",
              " 0.009479373693466187,\n",
              " 0.9379875659942627,\n",
              " 0.024494171142578125,\n",
              " 0.05160409212112427,\n",
              " 0.9761915802955627,\n",
              " 0.04909837245941162,\n",
              " 0.9141402840614319,\n",
              " 0.9572200775146484,\n",
              " 0.4390118420124054,\n",
              " 0.9723713994026184,\n",
              " 0.5390625596046448,\n",
              " 0.011152535676956177,\n",
              " 0.9506506323814392,\n",
              " 0.7045782804489136,\n",
              " 0.014031410217285156,\n",
              " 0.01114007830619812,\n",
              " 0.0108262300491333,\n",
              " 0.02068161964416504,\n",
              " 0.017652571201324463,\n",
              " 0.03984653949737549,\n",
              " 0.04163658618927002,\n",
              " 0.9493257999420166,\n",
              " 0.9708783030509949,\n",
              " 0.009786874055862427,\n",
              " 0.45913299918174744,\n",
              " 0.2564640939235687,\n",
              " 0.3363235592842102,\n",
              " 0.11620333790779114,\n",
              " 0.019226938486099243,\n",
              " 0.00894242525100708,\n",
              " 0.09272512793540955,\n",
              " 0.974287211894989,\n",
              " 0.010248422622680664,\n",
              " 0.6805722713470459,\n",
              " 0.9054852724075317,\n",
              " 0.5974675416946411,\n",
              " 0.16759321093559265,\n",
              " 0.9739765524864197,\n",
              " 0.48518458008766174,\n",
              " 0.6563345193862915,\n",
              " 0.021553635597229004,\n",
              " 0.9743879437446594,\n",
              " 0.9719967842102051,\n",
              " 0.9773626327514648,\n",
              " 0.9761835932731628,\n",
              " 0.016819506883621216,\n",
              " 0.17151299118995667,\n",
              " 0.9736448526382446,\n",
              " 0.8598285913467407,\n",
              " 0.976020097732544,\n",
              " 0.9740003347396851,\n",
              " 0.034749895334243774,\n",
              " 0.9566894769668579,\n",
              " 0.023381412029266357,\n",
              " 0.025252848863601685,\n",
              " 0.8910967111587524,\n",
              " 0.02022424340248108,\n",
              " 0.009562492370605469,\n",
              " 0.009514182806015015,\n",
              " 0.06660190224647522,\n",
              " 0.7711494565010071,\n",
              " 0.19478505849838257,\n",
              " 0.5634063482284546,\n",
              " 0.8227746486663818,\n",
              " 0.011829107999801636,\n",
              " 0.11260116100311279,\n",
              " 0.9491351246833801,\n",
              " 0.9737368822097778,\n",
              " 0.32575148344039917,\n",
              " 0.9464442729949951,\n",
              " 0.8978291749954224,\n",
              " 0.9282435178756714,\n",
              " 0.9404277801513672,\n",
              " 0.05307835340499878,\n",
              " 0.9723383188247681,\n",
              " 0.970700204372406,\n",
              " 0.9766459465026855,\n",
              " 0.568865954875946,\n",
              " 0.7039299011230469,\n",
              " 0.9756292104721069,\n",
              " 0.94185471534729,\n",
              " 0.00931444764137268,\n",
              " 0.9775561094284058,\n",
              " 0.013411343097686768,\n",
              " 0.012452781200408936,\n",
              " 0.014784783124923706,\n",
              " 0.009924441576004028,\n",
              " 0.9766685366630554,\n",
              " 0.009614348411560059,\n",
              " 0.8629715442657471,\n",
              " 0.039499133825302124,\n",
              " 0.9772220849990845,\n",
              " 0.009583771228790283,\n",
              " 0.5584883093833923,\n",
              " 0.5529283881187439,\n",
              " 0.010775446891784668,\n",
              " 0.9760571718215942,\n",
              " 0.14768585562705994,\n",
              " 0.06477320194244385,\n",
              " 0.7925058007240295,\n",
              " 0.09729135036468506,\n",
              " 0.9585375189781189,\n",
              " 0.9729326367378235,\n",
              " 0.19723188877105713,\n",
              " 0.9227874875068665,\n",
              " 0.9769356846809387,\n",
              " 0.9742264151573181,\n",
              " 0.010926991701126099,\n",
              " 0.03787919878959656,\n",
              " 0.9708857536315918,\n",
              " 0.012580960988998413,\n",
              " 0.042508989572525024,\n",
              " 0.9689891338348389,\n",
              " 0.09399735927581787,\n",
              " 0.9427831172943115,\n",
              " 0.9767740964889526,\n",
              " 0.9737952947616577,\n",
              " 0.975438117980957,\n",
              " 0.014675527811050415,\n",
              " 0.1037851870059967,\n",
              " 0.05889606475830078,\n",
              " 0.029381781816482544,\n",
              " 0.975272536277771,\n",
              " 0.009936094284057617,\n",
              " 0.0099143385887146,\n",
              " 0.8779251575469971,\n",
              " 0.07179185748100281,\n",
              " 0.010138481855392456,\n",
              " 0.8526065945625305,\n",
              " 0.3583887219429016,\n",
              " 0.021757543087005615,\n",
              " 0.6549404859542847,\n",
              " 0.9672229290008545,\n",
              " 0.9761841297149658,\n",
              " 0.009722858667373657,\n",
              " 0.9733651876449585,\n",
              " 0.9732441902160645,\n",
              " 0.009725779294967651,\n",
              " 0.9076133370399475,\n",
              " 0.9749593138694763,\n",
              " 0.02402511239051819,\n",
              " 0.010072976350784302,\n",
              " 0.7143772840499878,\n",
              " 0.9770157337188721,\n",
              " 0.03819680213928223,\n",
              " 0.06513410806655884,\n",
              " 0.054227083921432495,\n",
              " 0.024199724197387695,\n",
              " 0.2676214873790741,\n",
              " 0.011238932609558105,\n",
              " 0.9778072834014893,\n",
              " 0.7575802206993103,\n",
              " 0.01182866096496582,\n",
              " 0.008867263793945312,\n",
              " 0.9767974019050598,\n",
              " 0.9349822998046875,\n",
              " 0.012462854385375977,\n",
              " 0.9395499229431152,\n",
              " 0.8988711833953857,\n",
              " 0.009616255760192871,\n",
              " 0.9736930131912231,\n",
              " 0.8638631105422974,\n",
              " 0.022501111030578613,\n",
              " 0.21020638942718506,\n",
              " 0.012013137340545654,\n",
              " 0.010717630386352539,\n",
              " 0.9760114550590515,\n",
              " 0.977215051651001,\n",
              " 0.11517637968063354,\n",
              " 0.7720128893852234,\n",
              " 0.9730243682861328,\n",
              " 0.6047693490982056,\n",
              " 0.008919119834899902,\n",
              " 0.009227961301803589,\n",
              " 0.6739242672920227,\n",
              " 0.4420303702354431,\n",
              " 0.011224061250686646,\n",
              " 0.030163615942001343,\n",
              " 0.011152029037475586,\n",
              " 0.9690852165222168,\n",
              " 0.012591749429702759,\n",
              " 0.8337541818618774,\n",
              " 0.663219690322876,\n",
              " 0.370755136013031,\n",
              " 0.5832171440124512,\n",
              " 0.9662871360778809,\n",
              " 0.17683669924736023,\n",
              " 0.9746748208999634,\n",
              " 0.008886486291885376,\n",
              " 0.20423266291618347,\n",
              " 0.975547194480896,\n",
              " 0.7425259947776794,\n",
              " 0.9738439917564392,\n",
              " 0.022654324769973755,\n",
              " 0.594368577003479,\n",
              " 0.6878470182418823,\n",
              " 0.38773834705352783,\n",
              " 0.977258026599884,\n",
              " 0.032435446977615356,\n",
              " 0.9770400524139404,\n",
              " 0.9144863486289978,\n",
              " 0.417294979095459,\n",
              " 0.011756569147109985,\n",
              " 0.1394575834274292,\n",
              " 0.011268645524978638,\n",
              " 0.012565016746520996,\n",
              " 0.03617444634437561,\n",
              " 0.012645334005355835,\n",
              " 0.48333683609962463,\n",
              " 0.014266043901443481,\n",
              " 0.020646333694458008,\n",
              " 0.7619214653968811,\n",
              " 0.15683698654174805,\n",
              " 0.9684427976608276,\n",
              " 0.9763725996017456,\n",
              " 0.010662734508514404,\n",
              " 0.748397946357727,\n",
              " 0.015527129173278809,\n",
              " 0.24173614382743835,\n",
              " 0.020196199417114258,\n",
              " 0.010005742311477661,\n",
              " 0.9737182259559631,\n",
              " 0.011921525001525879,\n",
              " 0.9751893281936646,\n",
              " 0.9706065654754639,\n",
              " 0.18744635581970215,\n",
              " 0.01630273461341858,\n",
              " 0.9728173017501831,\n",
              " 0.9751225113868713,\n",
              " 0.9761396646499634,\n",
              " 0.9702494144439697,\n",
              " 0.9761976599693298,\n",
              " 0.9701708555221558,\n",
              " 0.011586278676986694,\n",
              " 0.014756828546524048,\n",
              " 0.5381329655647278,\n",
              " 0.014697074890136719,\n",
              " 0.011646926403045654,\n",
              " 0.016616791486740112,\n",
              " 0.2078154981136322,\n",
              " 0.9585782885551453,\n",
              " 0.9106564521789551,\n",
              " 0.02196979522705078,\n",
              " 0.010298311710357666,\n",
              " 0.00966566801071167,\n",
              " 0.9256582856178284,\n",
              " 0.9729263782501221,\n",
              " 0.14002323150634766,\n",
              " 0.9759529829025269,\n",
              " 0.9637652635574341,\n",
              " 0.019463717937469482,\n",
              " 0.977612316608429,\n",
              " 0.009008318185806274,\n",
              " 0.00961601734161377,\n",
              " 0.7568145990371704,\n",
              " 0.009698092937469482,\n",
              " 0.016431421041488647,\n",
              " 0.011468172073364258,\n",
              " 0.019299358129501343,\n",
              " 0.5802788138389587,\n",
              " 0.6343763470649719,\n",
              " 0.010463893413543701,\n",
              " 0.016115576028823853,\n",
              " 0.01019984483718872,\n",
              " 0.964569091796875,\n",
              " 0.39021414518356323,\n",
              " 0.7817904353141785,\n",
              " 0.9764236211776733,\n",
              " 0.18846577405929565,\n",
              " 0.9724262952804565,\n",
              " 0.976558268070221,\n",
              " 0.012014210224151611,\n",
              " 0.03504955768585205,\n",
              " 0.9755570888519287,\n",
              " 0.9406123161315918,\n",
              " 0.5895554423332214,\n",
              " 0.06303733587265015,\n",
              " 0.010549038648605347,\n",
              " 0.009014874696731567,\n",
              " 0.9723098278045654,\n",
              " 0.02249947190284729,\n",
              " 0.9606429934501648,\n",
              " 0.012355387210845947,\n",
              " 0.08359077572822571,\n",
              " 0.971575140953064,\n",
              " 0.010445833206176758,\n",
              " 0.3267657160758972,\n",
              " 0.6465932130813599,\n",
              " 0.011510878801345825,\n",
              " 0.972506046295166,\n",
              " 0.4235241413116455,\n",
              " 0.031083017587661743,\n",
              " 0.9763330817222595,\n",
              " 0.9756275415420532,\n",
              " 0.25156262516975403,\n",
              " 0.01484176516532898,\n",
              " 0.04282680153846741,\n",
              " 0.9693453907966614,\n",
              " 0.02140948176383972,\n",
              " 0.9682930707931519,\n",
              " 0.905171275138855,\n",
              " 0.38266614079475403,\n",
              " 0.02773284912109375,\n",
              " 0.9560527801513672,\n",
              " 0.9732463359832764,\n",
              " 0.018321722745895386,\n",
              " 0.9768185615539551,\n",
              " 0.8140544891357422,\n",
              " 0.6903899908065796,\n",
              " 0.3340543210506439,\n",
              " 0.010566025972366333,\n",
              " 0.010470449924468994,\n",
              " 0.010325044393539429,\n",
              " 0.28491389751434326,\n",
              " 0.9396803379058838,\n",
              " 0.18477556109428406,\n",
              " 0.832473874092102,\n",
              " 0.01231423020362854,\n",
              " 0.012135177850723267,\n",
              " 0.9759023189544678,\n",
              " 0.9217262864112854,\n",
              " 0.9506358504295349,\n",
              " 0.9735778570175171,\n",
              " 0.07095399498939514,\n",
              " 0.9744654893875122,\n",
              " 0.019808560609817505,\n",
              " 0.9751238226890564,\n",
              " 0.012316018342971802,\n",
              " 0.9631974101066589,\n",
              " 0.013406097888946533,\n",
              " 0.018742471933364868,\n",
              " 0.9718966484069824,\n",
              " 0.011670053005218506,\n",
              " 0.014507651329040527,\n",
              " 0.009609639644622803,\n",
              " 0.2370731234550476,\n",
              " 0.020015060901641846,\n",
              " 0.9748609662055969,\n",
              " 0.009743362665176392,\n",
              " 0.013471633195877075,\n",
              " 0.010010719299316406,\n",
              " 0.009255707263946533,\n",
              " 0.9747694134712219,\n",
              " 0.9723542928695679,\n",
              " 0.9770404100418091,\n",
              " 0.05380389094352722,\n",
              " 0.6684093475341797,\n",
              " 0.9043113589286804,\n",
              " 0.974402904510498,\n",
              " 0.9672119617462158,\n",
              " 0.9728946685791016,\n",
              " 0.4236031770706177,\n",
              " 0.9455288648605347,\n",
              " 0.9600142240524292,\n",
              " 0.3575604557991028,\n",
              " 0.9760873317718506,\n",
              " 0.9564275145530701,\n",
              " 0.009062469005584717,\n",
              " 0.97382652759552,\n",
              " 0.009522438049316406,\n",
              " 0.00933733582496643,\n",
              " 0.03824445605278015,\n",
              " 0.973341703414917,\n",
              " 0.9772106409072876,\n",
              " 0.9757629632949829,\n",
              " 0.009864747524261475,\n",
              " 0.9525527954101562,\n",
              " 0.9462665319442749,\n",
              " 0.5033779144287109,\n",
              " 0.12673133611679077,\n",
              " 0.2563914358615875,\n",
              " 0.009913772344589233,\n",
              " 0.022318780422210693,\n",
              " 0.9296741485595703,\n",
              " 0.345512330532074,\n",
              " 0.9759453535079956,\n",
              " 0.7795723080635071,\n",
              " 0.596571147441864,\n",
              " 0.016357213258743286,\n",
              " 0.009751737117767334,\n",
              " 0.9764085412025452,\n",
              " 0.114784836769104,\n",
              " 0.02433726191520691,\n",
              " 0.013298273086547852,\n",
              " 0.9721356630325317,\n",
              " 0.47713422775268555,\n",
              " 0.9701324701309204,\n",
              " 0.9691705703735352,\n",
              " 0.37308043241500854,\n",
              " 0.9538310766220093,\n",
              " 0.03143793344497681,\n",
              " 0.9701262712478638,\n",
              " 0.02738720178604126,\n",
              " 0.01727592945098877,\n",
              " 0.38663026690483093,\n",
              " 0.4140907824039459,\n",
              " 0.0220220685005188,\n",
              " 0.42690926790237427,\n",
              " 0.701492190361023,\n",
              " 0.26125383377075195,\n",
              " 0.3388948142528534,\n",
              " 0.5035691857337952,\n",
              " 0.016171395778656006,\n",
              " 0.07098415493965149,\n",
              " 0.010894685983657837,\n",
              " 0.9764174818992615,\n",
              " 0.38534438610076904,\n",
              " 0.1256699562072754,\n",
              " 0.13508903980255127,\n",
              " 0.010816901922225952,\n",
              " 0.03651982545852661,\n",
              " 0.04115450382232666,\n",
              " 0.2768678665161133,\n",
              " 0.012541800737380981,\n",
              " 0.9661495685577393,\n",
              " 0.9307413101196289,\n",
              " 0.9585168361663818,\n",
              " 0.9653612375259399,\n",
              " 0.9761309027671814,\n",
              " 0.9704271554946899,\n",
              " 0.011958539485931396,\n",
              " 0.9749401807785034,\n",
              " 0.9719635248184204,\n",
              " 0.7616245746612549,\n",
              " 0.009386032819747925,\n",
              " 0.015170395374298096,\n",
              " 0.01391550898551941,\n",
              " 0.00921890139579773,\n",
              " 0.010867208242416382,\n",
              " 0.9767792224884033,\n",
              " 0.9764279127120972,\n",
              " 0.23044297099113464,\n",
              " 0.039675235748291016,\n",
              " 0.12914308905601501,\n",
              " 0.7717878818511963,\n",
              " 0.00967898964881897,\n",
              " 0.014646947383880615,\n",
              " 0.014331072568893433,\n",
              " 0.9773123860359192,\n",
              " 0.010379135608673096,\n",
              " 0.9579019546508789,\n",
              " 0.16943538188934326,\n",
              " 0.9756157994270325,\n",
              " 0.7256729602813721,\n",
              " 0.9744622111320496,\n",
              " 0.009177684783935547,\n",
              " 0.7377233505249023,\n",
              " 0.7206301093101501,\n",
              " 0.6530529856681824,\n",
              " 0.9762603640556335,\n",
              " 0.03134956955909729,\n",
              " 0.010588079690933228,\n",
              " 0.01089903712272644,\n",
              " 0.016440987586975098,\n",
              " 0.9534972906112671,\n",
              " 0.30308035016059875,\n",
              " 0.972460150718689,\n",
              " 0.9466798901557922,\n",
              " 0.5909218192100525,\n",
              " 0.009580403566360474,\n",
              " 0.016523748636245728,\n",
              " 0.32088539004325867,\n",
              " 0.958959698677063,\n",
              " 0.06722909212112427,\n",
              " 0.976664662361145,\n",
              " 0.9751778841018677,\n",
              " 0.9568729996681213,\n",
              " 0.9607893824577332,\n",
              " 0.009008646011352539,\n",
              " 0.9660379886627197,\n",
              " 0.13184690475463867,\n",
              " 0.21607697010040283,\n",
              " 0.6330008506774902,\n",
              " 0.24089542031288147,\n",
              " 0.018852829933166504,\n",
              " 0.9750702381134033,\n",
              " 0.010479986667633057,\n",
              " 0.011184751987457275,\n",
              " 0.010109871625900269,\n",
              " 0.14333337545394897,\n",
              " 0.010121703147888184,\n",
              " 0.9724671840667725,\n",
              " 0.9755851030349731,\n",
              " 0.9765172600746155,\n",
              " 0.9766047596931458,\n",
              " 0.10371506214141846,\n",
              " 0.010126888751983643,\n",
              " 0.2391694188117981,\n",
              " 0.9276833534240723,\n",
              " 0.06829330325126648,\n",
              " 0.9638527631759644,\n",
              " 0.9138521552085876,\n",
              " 0.013085871934890747,\n",
              " 0.00999140739440918,\n",
              " 0.9768494367599487,\n",
              " 0.008926212787628174,\n",
              " 0.009958326816558838,\n",
              " 0.1844375729560852,\n",
              " 0.9747390747070312,\n",
              " 0.008704781532287598,\n",
              " 0.9529569149017334,\n",
              " 0.9759845733642578,\n",
              " 0.009741127490997314,\n",
              " 0.011265814304351807,\n",
              " 0.3991253077983856,\n",
              " 0.9743831157684326,\n",
              " 0.9620190858840942,\n",
              " 0.01042109727859497,\n",
              " 0.8322082757949829,\n",
              " 0.13173845410346985,\n",
              " 0.011277085170149803,\n",
              " 0.010397225618362427,\n",
              " 0.15350773930549622,\n",
              " 0.9616680145263672,\n",
              " 0.028526365756988525,\n",
              " 0.010125219821929932,\n",
              " 0.5395786166191101,\n",
              " 0.1610436737537384,\n",
              " 0.553753137588501,\n",
              " 0.8576942682266235,\n",
              " 0.24898892641067505,\n",
              " 0.9769301414489746,\n",
              " 0.009532272815704346,\n",
              " 0.9574181437492371,\n",
              " 0.9749698638916016,\n",
              " 0.9081884026527405,\n",
              " 0.011212646961212158,\n",
              " 0.7665894031524658,\n",
              " 0.8550959825515747,\n",
              " 0.015620976686477661,\n",
              " 0.010852187871932983,\n",
              " 0.011554330587387085,\n",
              " 0.976686954498291,\n",
              " 0.9719128608703613,\n",
              " 0.900962233543396,\n",
              " 0.9760239124298096,\n",
              " 0.9720748662948608,\n",
              " 0.00928586721420288,\n",
              " 0.5371994376182556,\n",
              " 0.9767433404922485,\n",
              " 0.831424355506897,\n",
              " 0.01115599274635315,\n",
              " 0.5127890110015869,\n",
              " 0.020803064107894897,\n",
              " 0.9319312572479248,\n",
              " 0.010327160358428955,\n",
              " 0.015717238187789917,\n",
              " 0.009869873523712158,\n",
              " 0.6336867213249207,\n",
              " 0.9757732152938843,\n",
              " 0.3756851553916931,\n",
              " 0.009130299091339111,\n",
              " 0.9754743576049805,\n",
              " 0.009731829166412354,\n",
              " 0.011752218008041382,\n",
              " 0.009702861309051514,\n",
              " 0.24688789248466492,\n",
              " 0.976499080657959,\n",
              " 0.957629919052124,\n",
              " 0.8519478440284729,\n",
              " 0.9767232537269592,\n",
              " 0.009073644876480103,\n",
              " 0.05446633696556091,\n",
              " 0.009744137525558472,\n",
              " 0.009173423051834106,\n",
              " 0.08680745959281921,\n",
              " 0.9764039516448975,\n",
              " 0.011201083660125732,\n",
              " 0.7878552675247192,\n",
              " 0.012503772974014282,\n",
              " 0.08676832914352417,\n",
              " 0.08953368663787842,\n",
              " 0.03721308708190918,\n",
              " 0.37704914808273315,\n",
              " 0.32289573550224304,\n",
              " 0.021822750568389893,\n",
              " 0.010603487491607666,\n",
              " 0.021202534437179565,\n",
              " 0.32923099398612976,\n",
              " 0.02407383918762207,\n",
              " 0.9607794880867004,\n",
              " 0.9763984084129333,\n",
              " 0.5126672983169556,\n",
              " 0.02102711796760559,\n",
              " 0.3476618528366089,\n",
              " 0.9763450026512146,\n",
              " 0.9765299558639526,\n",
              " 0.678565263748169,\n",
              " 0.9459254741668701,\n",
              " 0.011952519416809082,\n",
              " 0.9761861562728882,\n",
              " 0.009116262197494507,\n",
              " 0.3966815173625946,\n",
              " 0.4481486976146698,\n",
              " 0.9769812822341919,\n",
              " 0.011051535606384277,\n",
              " 0.9746179580688477,\n",
              " 0.023577064275741577,\n",
              " 0.84626704454422,\n",
              " 0.5165380835533142,\n",
              " 0.439725786447525,\n",
              " 0.9177794456481934,\n",
              " 0.010530412197113037,\n",
              " 0.97119140625,\n",
              " 0.7807685136795044,\n",
              " 0.08268424868583679,\n",
              " 0.9594303965568542,\n",
              " 0.7253344655036926,\n",
              " 0.6614034175872803,\n",
              " 0.8379294872283936,\n",
              " 0.848604142665863,\n",
              " 0.975346565246582,\n",
              " 0.019289851188659668,\n",
              " 0.01128724217414856,\n",
              " 0.24543863534927368,\n",
              " 0.010214745998382568,\n",
              " 0.9685307741165161,\n",
              " 0.270222544670105,\n",
              " 0.9535043835639954,\n",
              " 0.28804153203964233,\n",
              " 0.9760428071022034,\n",
              " 0.040466517210006714,\n",
              " 0.9557327032089233,\n",
              " 0.8072975873947144,\n",
              " 0.9744139313697815,\n",
              " 0.013851374387741089,\n",
              " 0.9752602577209473,\n",
              " 0.011739939451217651,\n",
              " 0.8845697045326233,\n",
              " 0.017718791961669922,\n",
              " 0.009489983320236206,\n",
              " 0.3163897395133972,\n",
              " 0.5512898564338684,\n",
              " 0.975227415561676,\n",
              " 0.9768234491348267,\n",
              " 0.47400206327438354,\n",
              " 0.16162532567977905,\n",
              " 0.04093948006629944,\n",
              " 0.011460036039352417,\n",
              " 0.011972129344940186,\n",
              " 0.36485788226127625,\n",
              " 0.37282779812812805,\n",
              " 0.9671673774719238,\n",
              " 0.40659675002098083,\n",
              " 0.9680120944976807,\n",
              " 0.9742382764816284,\n",
              " 0.030556529760360718,\n",
              " 0.9772158861160278,\n",
              " 0.09155189990997314,\n",
              " 0.9567675590515137,\n",
              " 0.01100236177444458,\n",
              " 0.01226729154586792,\n",
              " 0.9469764232635498,\n",
              " 0.9714489579200745,\n",
              " 0.9732680320739746,\n",
              " 0.9739023447036743,\n",
              " 0.9723074436187744,\n",
              " 0.9756889343261719,\n",
              " 0.9436898827552795,\n",
              " 0.9714610576629639,\n",
              " 0.11594453454017639,\n",
              " 0.9388502836227417,\n",
              " 0.08840152621269226,\n",
              " 0.012971878051757812,\n",
              " 0.2248157560825348,\n",
              " 0.02180686593055725,\n",
              " 0.9751749038696289,\n",
              " 0.01106804609298706,\n",
              " 0.9769429564476013,\n",
              " 0.9733995199203491,\n",
              " 0.04588541388511658,\n",
              " 0.9687992334365845,\n",
              " 0.01263284683227539,\n",
              " 0.9753537774085999,\n",
              " 0.9752167463302612,\n",
              " 0.011144757270812988,\n",
              " 0.9761406183242798,\n",
              " 0.9756349325180054,\n",
              " 0.01947176456451416,\n",
              " 0.28377044200897217,\n",
              " 0.00966838002204895,\n",
              " 0.010302156209945679,\n",
              " 0.9764541387557983,\n",
              " 0.9759632349014282,\n",
              " 0.04759848117828369,\n",
              " 0.1960478127002716,\n",
              " 0.47424745559692383,\n",
              " 0.9773730039596558,\n",
              " 0.010438203811645508,\n",
              " 0.9778499603271484,\n",
              " 0.009657680988311768,\n",
              " 0.49181631207466125,\n",
              " 0.805335283279419,\n",
              " 0.08690953254699707,\n",
              " 0.010745823383331299,\n",
              " 0.018894314765930176,\n",
              " 0.012294501066207886,\n",
              " 0.9700462818145752,\n",
              " 0.9344655871391296,\n",
              " 0.008683204650878906,\n",
              " 0.9691863059997559,\n",
              " 0.9748433828353882,\n",
              " 0.9743894338607788,\n",
              " 0.00993412733078003,\n",
              " 0.971021294593811,\n",
              " 0.9712042212486267,\n",
              " 0.9761336445808411,\n",
              " 0.255136638879776,\n",
              " 0.9317255020141602,\n",
              " 0.184964120388031,\n",
              " 0.25323495268821716,\n",
              " 0.947211503982544,\n",
              " 0.9409502744674683,\n",
              " 0.973931074142456,\n",
              " 0.9744912385940552,\n",
              " 0.009634315967559814,\n",
              " 0.9772161245346069,\n",
              " 0.9754946827888489,\n",
              " 0.009636551141738892,\n",
              " 0.009189516305923462,\n",
              " 0.013904005289077759,\n",
              " 0.010488390922546387,\n",
              " 0.93585205078125,\n",
              " 0.008939415216445923,\n",
              " 0.8407793045043945,\n",
              " 0.009964972734451294,\n",
              " 0.013923555612564087,\n",
              " 0.9746385216712952,\n",
              " 0.9734191298484802,\n",
              " 0.963547945022583,\n",
              " 0.3721829354763031,\n",
              " 0.24390935897827148,\n",
              " 0.9565365314483643,\n",
              " 0.45984795689582825,\n",
              " 0.014324754476547241,\n",
              " 0.010534793138504028,\n",
              " 0.864829421043396,\n",
              " 0.9728831052780151,\n",
              " 0.945212721824646,\n",
              " 0.9747755527496338,\n",
              " 0.9721170663833618,\n",
              " 0.9156119227409363,\n",
              " 0.9742369055747986,\n",
              " 0.009965300559997559,\n",
              " 0.33957427740097046,\n",
              " 0.9579300880432129,\n",
              " 0.009638160467147827,\n",
              " 0.02179136872291565,\n",
              " 0.8966581225395203,\n",
              " 0.13766133785247803,\n",
              " 0.33410167694091797,\n",
              " 0.01003316044807434,\n",
              " 0.7369739413261414,\n",
              " 0.16416773200035095,\n",
              " 0.29735779762268066,\n",
              " 0.03813627362251282,\n",
              " 0.9751294851303101,\n",
              " 0.010395467281341553,\n",
              " 0.35403865575790405,\n",
              " 0.01873071864247322,\n",
              " 0.04347832873463631,\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "metadata": {
        "id": "Mx1Qp9LTCue1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # \n",
        "predictions_combined = (pd.DataFrame(predictions1) + pd.DataFrame(predictions2) + pd.DataFrame(predictions3))/3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BDZzkmi3CufI",
        "colab_type": "code",
        "outputId": "83ade636-ffe4-4322-b31b-81ffd2c2ffcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "# predictions_combined.head()"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.824558</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.176947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.576638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.768944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.819436</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0\n",
              "0  0.824558\n",
              "1  0.176947\n",
              "2  0.576638\n",
              "3  0.768944\n",
              "4  0.819436"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "metadata": {
        "id": "_EUWPkDcOCzt",
        "colab_type": "code",
        "outputId": "382cb93e-0eac-4856-a43a-dd4788076253",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "# test.head()"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12311_10</td>\n",
              "      <td>Naturally in a film who's main themes are of m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8348_2</td>\n",
              "      <td>This movie is a disaster within a disaster fil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5828_4</td>\n",
              "      <td>All in all, this is a movie for kids. We saw i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7186_2</td>\n",
              "      <td>Afraid of the Dark left me with the impression...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12128_7</td>\n",
              "      <td>A very accurate depiction of small time mob li...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id                                             review\n",
              "0  12311_10  Naturally in a film who's main themes are of m...\n",
              "1    8348_2  This movie is a disaster within a disaster fil...\n",
              "2    5828_4  All in all, this is a movie for kids. We saw i...\n",
              "3    7186_2  Afraid of the Dark left me with the impression...\n",
              "4   12128_7  A very accurate depiction of small time mob li..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "metadata": {
        "id": "qq8h2XNQOLfC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "brinks_test = pd.read_excel(\"gdrive/My Drive/ML Data/brinks_sample (1).xls\", delimiter=\"\\t\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oMGlcqaUcaHg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3P44ysFiOgJ6",
        "colab_type": "code",
        "outputId": "ba9ee624-c014-4770-bad6-53f40b5c83ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(brinks_test)"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1334"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "metadata": {
        "id": "a8Nyy6CrOi51",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def clean_test(text, remove_stopwords=True):\n",
        "    '''Clean the text, with the option to remove stopwords'''\n",
        "    \n",
        "    # Convert words to lower case and split them\n",
        "    text = str(text).lower().split()\n",
        "\n",
        "    # Optionally, remove stop words\n",
        "    if remove_stopwords:\n",
        "        stops = set(stopwords.words(\"english\"))\n",
        "        text = [w for w in text if not w in stops]\n",
        "    \n",
        "    text = \" \".join(text)\n",
        "\n",
        "    # Clean the text\n",
        "    text = re.sub(r\"<br />\", \" \", text)\n",
        "    text = re.sub(r\"[^a-z]\", \" \", text)\n",
        "    text = re.sub(r\"   \", \" \", text) # Remove any extra spaces\n",
        "    text = re.sub(r\"  \", \" \", text)\n",
        "    \n",
        "    # Remove punctuation from text\n",
        "    text = ''.join([c for c in text if c not in punctuation])\n",
        "    \n",
        "    # Return a list of words\n",
        "    return(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6jVXT1lTOwAQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "brinks_clean = []\n",
        "for review in brinks_test.Review:\n",
        "    brinks_clean.append(clean_test(review))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Dfv3PhXGO4Zq",
        "colab_type": "code",
        "outputId": "f942d0be-ec56-4eb8-8152-3caf142baeca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "brinks_test_seq = tokenizer.texts_to_sequences(brinks_clean)\n",
        "print(\"test_seq is complete\")"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_seq is complete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uQoTtLUePEvE",
        "colab_type": "code",
        "outputId": "b991b6b3-8240-4dd5-9da2-26cd0017639f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "brinks_test_seq[1]"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[617, 2501, 11990, 3656]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "metadata": {
        "id": "3jzNu2xHPGy2",
        "colab_type": "code",
        "outputId": "e75c9e43-22e9-4d48-e925-a7758d1833d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "brinks_clean[1]"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'talk customers updating equipment '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "metadata": {
        "id": "JvFBbnKGPMSY",
        "colab_type": "code",
        "outputId": "9e810086-61fc-4071-a333-1d27ec4b37b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "brinks_pad = pad_sequences(brinks_test_seq, maxlen = 200)\n",
        "print(\"test_pad is complete.\")"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_pad is complete.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JiUoHlvoPV4R",
        "colab_type": "code",
        "outputId": "731a596a-6d89-4f3d-d616-57e2fc56674b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "cell_type": "code",
      "source": [
        "brinks_pad[2]"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0, 2276, 9566, 2604, 5847, 1215, 1548, 1713,  117,   38, 6614,\n",
              "       2604, 1527], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "metadata": {
        "id": "5b4JlDIdPXRs",
        "colab_type": "code",
        "outputId": "0a7004a0-7adc-40d1-b255-2d6ae3a606aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "cell_type": "code",
      "source": [
        "test_pad[1]"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     2,  1619,   685,  1619,     3,   249,\n",
              "          14,   146,    65,  3498,  1308,   153,   227,   610,   184,\n",
              "           1,    15,   615,  1564,  7772,  3597,   161,  6044,  3597,\n",
              "         161,    82,    42,   699,   203,  7772, 19885,  1422,  7772,\n",
              "        3030,   802,   184,   572,  3097,     4,  3015,    28,   150,\n",
              "          81,   191,   135,     2,    13,   390,  3097,   862,   655,\n",
              "         196,   160,     3,   311,    55,    81,     7,   245,   673,\n",
              "         163,   191,  1844,   275,  3333,  1588,   655,  1008,   364,\n",
              "        5236,    11,     2,   293,   164,    86,   153,     5,  1013,\n",
              "        4104,   324,    37,   424,    40,    86,   153,   972,     9,\n",
              "        3498,  1555], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "T3DC8rDFPzpJ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def b_make_predictions(lstm_size, multiple_fc, fc_units, checkpoint):\n",
        "    '''Predict the sentiment of the testing data'''\n",
        "    \n",
        "    # Record all of the predictions\n",
        "    all_preds = []\n",
        "\n",
        "    model = build_rnn(n_words = n_words, \n",
        "                      embed_size = embed_size,\n",
        "                      batch_size = batch_size,\n",
        "                      lstm_size = lstm_size,\n",
        "                      num_layers = num_layers,\n",
        "                      dropout = dropout,\n",
        "                      learning_rate = learning_rate,\n",
        "                      multiple_fc = multiple_fc,\n",
        "                      fc_units = fc_units) \n",
        "    \n",
        "    with tf.Session() as sess:\n",
        "        saver = tf.train.Saver()\n",
        "        # Load the model\n",
        "        saver.restore(sess, checkpoint)\n",
        "        test_state = sess.run(model.initial_state)\n",
        "        for _, x in enumerate(get_test_batches(brinks_pad, batch_size), 1):\n",
        "            feed = {model.inputs: x,\n",
        "                    model.keep_prob: 1,\n",
        "                    model.initial_state: test_state}\n",
        "            predictions = sess.run(model.predictions, feed_dict=feed)\n",
        "            for pred in predictions:\n",
        "                all_preds.append(float(pred))\n",
        "                \n",
        "    return all_preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "A8cK6ePePzpP",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "checkpoint1 = \"gdrive/My Drive/Model_checkpoints/trial2/sentiment_ru=128,fcl=False,fcu=256.ckpt\"\n",
        "checkpoint2 = \"gdrive/My Drive/Model_checkpoints/trial2/sentiment_ru=128,fcl=False,fcu=128.ckpt\"\n",
        "checkpoint3 = \"gdrive/My Drive/Model_checkpoints/trial2/sentiment_ru=64,fcl=True,fcu=256.ckpt\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "35e78a6b-62bd-4bf7-f579-0fdfe8e65e98",
        "id": "vsF0G4pfPzpU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "# Make predictions using the best 3 models\n",
        "brinks_predictions1 = b_make_predictions(128, False, 256, checkpoint1)\n",
        "brinks_predictions2 = b_make_predictions(128, False, 128, checkpoint2)\n",
        "brinks_predictions3 = b_make_predictions(64, True, 256, checkpoint3)"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from gdrive/My Drive/Model_checkpoints/trial2/sentiment_ru=128,fcl=False,fcu=256.ckpt\n",
            "INFO:tensorflow:Restoring parameters from gdrive/My Drive/Model_checkpoints/trial2/sentiment_ru=128,fcl=False,fcu=128.ckpt\n",
            "INFO:tensorflow:Restoring parameters from gdrive/My Drive/Model_checkpoints/trial2/sentiment_ru=64,fcl=True,fcu=256.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cCosxu1K3TWy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "52aa199b-b906-4e70-cdd4-bf35e7238087"
      },
      "cell_type": "code",
      "source": [
        "len(brinks_predictions1)"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1250"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "_fhBapHoPzpf",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "brinks_predictions_combined1 = (pd.DataFrame(brinks_predictions1) + pd.DataFrame(brinks_predictions2) + pd.DataFrame(brinks_predictions3))/3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pi8L5EIxQUuo",
        "colab_type": "code",
        "outputId": "83b3295e-44a2-43b3-bd57-861d7a86494c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1969
        }
      },
      "cell_type": "code",
      "source": [
        "brinks_predictions_combined1"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.528725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.416811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.405012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.950734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.374442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.964146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.401709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.353279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.492759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.552810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.939846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.423084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.509597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.440159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.436992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.528725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.454819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.656267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.368208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.987537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.528725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.618598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.782373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.368144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.798663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.390138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.410164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.355739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.388129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.367470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1220</th>\n",
              "      <td>0.665644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1221</th>\n",
              "      <td>0.356410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1222</th>\n",
              "      <td>0.562737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1223</th>\n",
              "      <td>0.769234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1224</th>\n",
              "      <td>0.401174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1225</th>\n",
              "      <td>0.369386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1226</th>\n",
              "      <td>0.983722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1227</th>\n",
              "      <td>0.519874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1228</th>\n",
              "      <td>0.381878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1229</th>\n",
              "      <td>0.433770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1230</th>\n",
              "      <td>0.688797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1231</th>\n",
              "      <td>0.356349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1232</th>\n",
              "      <td>0.621170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1233</th>\n",
              "      <td>0.430592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1234</th>\n",
              "      <td>0.959883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1235</th>\n",
              "      <td>0.854016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1236</th>\n",
              "      <td>0.735427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1237</th>\n",
              "      <td>0.595862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1238</th>\n",
              "      <td>0.663767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1239</th>\n",
              "      <td>0.723508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1240</th>\n",
              "      <td>0.565804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1241</th>\n",
              "      <td>0.394061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1242</th>\n",
              "      <td>0.833546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1243</th>\n",
              "      <td>0.393046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1244</th>\n",
              "      <td>0.917139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1245</th>\n",
              "      <td>0.368600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1246</th>\n",
              "      <td>0.664553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1247</th>\n",
              "      <td>0.429809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1248</th>\n",
              "      <td>0.446392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1249</th>\n",
              "      <td>0.370085</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1250 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             0\n",
              "0     0.528725\n",
              "1     0.416811\n",
              "2     0.405012\n",
              "3     0.950734\n",
              "4     0.374442\n",
              "5     0.964146\n",
              "6     0.401709\n",
              "7     0.353279\n",
              "8     0.492759\n",
              "9     0.552810\n",
              "10    0.939846\n",
              "11    0.423084\n",
              "12    0.509597\n",
              "13    0.440159\n",
              "14    0.436992\n",
              "15    0.528725\n",
              "16    0.454819\n",
              "17    0.656267\n",
              "18    0.368208\n",
              "19    0.987537\n",
              "20    0.528725\n",
              "21    0.618598\n",
              "22    0.782373\n",
              "23    0.368144\n",
              "24    0.798663\n",
              "25    0.390138\n",
              "26    0.410164\n",
              "27    0.355739\n",
              "28    0.388129\n",
              "29    0.367470\n",
              "...        ...\n",
              "1220  0.665644\n",
              "1221  0.356410\n",
              "1222  0.562737\n",
              "1223  0.769234\n",
              "1224  0.401174\n",
              "1225  0.369386\n",
              "1226  0.983722\n",
              "1227  0.519874\n",
              "1228  0.381878\n",
              "1229  0.433770\n",
              "1230  0.688797\n",
              "1231  0.356349\n",
              "1232  0.621170\n",
              "1233  0.430592\n",
              "1234  0.959883\n",
              "1235  0.854016\n",
              "1236  0.735427\n",
              "1237  0.595862\n",
              "1238  0.663767\n",
              "1239  0.723508\n",
              "1240  0.565804\n",
              "1241  0.394061\n",
              "1242  0.833546\n",
              "1243  0.393046\n",
              "1244  0.917139\n",
              "1245  0.368600\n",
              "1246  0.664553\n",
              "1247  0.429809\n",
              "1248  0.446392\n",
              "1249  0.370085\n",
              "\n",
              "[1250 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 178
        }
      ]
    },
    {
      "metadata": {
        "id": "XPn_6LrqQW-w",
        "colab_type": "code",
        "outputId": "666746ae-1898-40a3-db59-0aeb0e3f3538",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "cell_type": "code",
      "source": [
        "brinks_test.head(10)"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review ID</th>\n",
              "      <th>Review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Talk to customers about updating equipment.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>When calling in to cancel an account you sho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>A pair monthly fee and my security system doe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>battery defect in central unit, did call and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>CHEAPER MONTHLY RATES!!!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>I have not Brinks service since approx June 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>I would like someone to come give me a new si...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>Some contacts for my representative and produ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>Up to date sine</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Review ID                                             Review\n",
              "0          1                                                   \n",
              "1          2        Talk to customers about updating equipment.\n",
              "2          3    When calling in to cancel an account you sho...\n",
              "3          4   A pair monthly fee and my security system doe...\n",
              "4          5   battery defect in central unit, did call and ...\n",
              "5          6                           CHEAPER MONTHLY RATES!!!\n",
              "6          7   I have not Brinks service since approx June 2...\n",
              "7          8   I would like someone to come give me a new si...\n",
              "8          9   Some contacts for my representative and produ...\n",
              "9         10                                   Up to date sine "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "metadata": {
        "id": "XaS3sPMwQYvV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "brinks_final = brinks_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qrLpEdNkRKiz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "brinks_final['predictions'] = brinks_predictions_combined1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J8tehTwB9zRr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "MYrX2Iy4RQeT",
        "colab_type": "code",
        "outputId": "3f6605d1-fc49-4507-96b1-ee579d3448e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "brinks_final.head()"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review ID</th>\n",
              "      <th>Review</th>\n",
              "      <th>predictions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td>0.528725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Talk to customers about updating equipment.</td>\n",
              "      <td>0.416811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>When calling in to cancel an account you sho...</td>\n",
              "      <td>0.405012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>A pair monthly fee and my security system doe...</td>\n",
              "      <td>0.950734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>battery defect in central unit, did call and ...</td>\n",
              "      <td>0.374442</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Review ID                                             Review  predictions\n",
              "0          1                                                        0.528725\n",
              "1          2        Talk to customers about updating equipment.     0.416811\n",
              "2          3    When calling in to cancel an account you sho...     0.405012\n",
              "3          4   A pair monthly fee and my security system doe...     0.950734\n",
              "4          5   battery defect in central unit, did call and ...     0.374442"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 185
        }
      ]
    },
    {
      "metadata": {
        "id": "aGPI_hAzRR5s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "brinks_final.to_excel(\"brinks_output.xlsx\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NfyZpNqzRik5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('brinks_output.xlsx')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GEgJ3EPIR3Tx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}